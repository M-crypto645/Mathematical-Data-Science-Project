{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from math import sqrt, pi\n",
    "from matplotlib.widgets import Slider, Button\n",
    "np.random.seed(3)\n",
    "\n",
    "colors = [\"#cccc00\", \"#006600\", \"m\", \"b\", \"r\"]\n",
    "\n",
    "def EM(data, K, m, n_iter = 25, return_all_iterations=False, random_choice=True):\n",
    "    N, M = data.shape # assume: N is number of data points, M is each data point's dimens\n",
    "\n",
    "    sigma_def = 3\n",
    "    likeli = []\n",
    "    #random initialization\n",
    "    if random_choice == True:\n",
    "        for mm in range(M):\n",
    "            m[:, mm] = np.random.uniform(np.min(data[:,mm]), np.max(data[:,mm]), (K, ))\n",
    "    Sigma = [sigma_def*np.eye(M) for kk in range(K)]\n",
    "    gamma = 1/K*np.ones((N,K), dtype=np.int32)\n",
    "    p = 1/K*np.ones((K,))\n",
    "    gamma_old = None\n",
    "    \n",
    "      \n",
    "    # if we want to get back all parameters for each single iteration    \n",
    "    if return_all_iterations:\n",
    "        Sigma_history = [[np.copy(Sigma[k]) for k in range(K)]]\n",
    "        m_history = np.zeros((1, K, M))\n",
    "        m_history[0, :, :] = m\n",
    "        gamma_history = np.zeros((1, N, K))\n",
    "        gamma_history[0, :, :] = gamma\n",
    "        p_history = np.zeros((1,K))\n",
    "        p_history[0, :] = p\n",
    "    # if we are only interested in the final clustering result        \n",
    "    else:\n",
    "        m_history = None\n",
    "        Sigma_history = None\n",
    "        gamma_history = None\n",
    "        p_history = None\n",
    "    \n",
    "    likeli_new = 0\n",
    "    for n in range(N):\n",
    "        x = data[n, :]\n",
    "        terms = np.array([p[k]*1/sqrt((2*pi)**M*np.linalg.det(Sigma[k])) * np.exp(-0.5*(x-m[k,:]) @ (np.linalg.inv(Sigma[k]) @ (x-m[k,:]))) for k in range(K)])\n",
    "        likeli_new = likeli_new + np.log(np.sum(terms))\n",
    "    likeli_new = 1/N * likeli_new\n",
    "    #print(likeli_new) \n",
    "    for it in range(n_iter):\n",
    "        likeli.append(likeli_new) \n",
    "        # assignment step\n",
    "        for n in range(N):\n",
    "            x = data[n, :]\n",
    "            terms = np.array([p[k]*1/sqrt((2*pi)**M*np.linalg.det(Sigma[k])) * np.exp(-0.5*(x-m[k,:]) @ (np.linalg.inv(Sigma[k]) @ (x-m[k,:]))) for k in range(K)])\n",
    "            gamma[n, :] = terms/np.sum(terms)\n",
    "        \n",
    "        \n",
    "            \n",
    "        if return_all_iterations:\n",
    "            gamma_history = np.append(gamma_history, [gamma], 0)\n",
    "        \n",
    "\n",
    "        # update step\n",
    "        means = np.dot(gamma.T, data)\n",
    "        Nk = [np.sum(gamma[:, k]) for k in range(K)]\n",
    "        m_new = np.array([ means[k, :]/Nk[k] for k in range(K)])\n",
    "        \n",
    "        # if we haven't moved a lot, break the loop and stick with current clustering\n",
    "        #if np.sum(np.sum((m-m_new)*(m-m_new))) < 10**-8:\n",
    "            #break\n",
    "        \n",
    "        m = m_new\n",
    "        \n",
    "        Sigma_new = [np.zeros((M, M)) for k in range(K)]\n",
    "        for k in range(K):\n",
    "            Sigmak = np.zeros((M,M))\n",
    "            for n in range(N):\n",
    "                x = data[n, :]\n",
    "                Sigmak += gamma[n, k] * np.dot((x-m[k,:]).reshape((-1,1)), (x-m[k,:]).reshape((1,-1)))\n",
    "            Sigma_new[k] = Sigmak/Nk[k]\n",
    "            if np.linalg.det(Sigma_new[k]) < 1e-10:\n",
    "                print(\"Covariance singularity!\")\n",
    "                return {\"success\": False, \"m\": m, \"Sigma\": Sigma, \"p\": p, \"gamma\": gamma, \"m_history\": m_history, \"Sigma_history\": Sigma_history, \"p_history\": p_history, \"gamma_history\": gamma_history, 'likelihood':likeli} # return a dictionary \n",
    "        \n",
    "        Sigma = [np.copy(Sigma_new[k]) for k in range(K)]\n",
    "\n",
    "        p = np.array([Nk[k]/N for k in range(K)])\n",
    "\n",
    "        \n",
    "        if return_all_iterations:\n",
    "            m_history = np.append(m_history, [m], 0)\n",
    "            Sigma_history.append([np.copy(Sigma_new[k]) for k in range(K)])\n",
    "            p_history = np.append(p_history, [p], 0)\n",
    "        likeli_old = likeli_new\n",
    "        likeli_new = 0\n",
    "        for n in range(N):\n",
    "            x = data[n, :]\n",
    "            terms = np.array([p[k]*1/sqrt((2*pi)**M*np.linalg.det(Sigma[k])) * np.exp(-0.5*(x-m[k,:]) @ (np.linalg.inv(Sigma[k]) @ (x-m[k,:]))) for k in range(K)])\n",
    "            likeli_new = likeli_new + np.log(np.sum(terms))\n",
    "        likeli_new = 1/N * likeli_new\n",
    "        #print(likeli_new)\n",
    "        if likeli_new > 10**8:\n",
    "            print(\"Error\")\n",
    "            return {\"success\": False, \"m\": m, \"Sigma\": Sigma, \"p\": p, \"gamma\": gamma, \"m_history\": m_history, \"Sigma_history\": Sigma_history, \"p_history\": p_history, \"gamma_history\": gamma_history, 'likelihood':likeli} # return a dictionary \n",
    "        if likeli_new - likeli_old < 10**-8:\n",
    "            break\n",
    "    return {\"success\": True, \"m\": m, \"Sigma\": Sigma, \"p\": p, \"gamma\": gamma, \"m_history\": m_history, \"Sigma_history\": Sigma_history, \"p_history\": p_history, \"gamma_history\": gamma_history, 'likelihood':likeli} # return a dictionary \n",
    "\n",
    "\n",
    "# matplotlib ellipse plotter (from matplotlib.org)\n",
    "\n",
    "\n",
    "def colorFader(c1,c2,mix=0): #fade (linear interpolate) from color c1 (at mix=0) to c2 (mix=1)\n",
    "    c1=np.array(mpl.colors.to_rgb(c1))\n",
    "    c2=np.array(mpl.colors.to_rgb(c2))\n",
    "    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)\n",
    "\n",
    "\n",
    "def plot_ellipse(mean, cov, ax, n_std=1.0, color='k', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of `x` and `y`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "\n",
    "    #cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        color=color, alpha = 0.05,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean[0], mean[1])\n",
    "    \n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test cases. Fiddle with parameters:\n",
    "    n_iter = 100\n",
    "    K = 2 # number of clusters\n",
    "    \n",
    "    option = 7 # select scenario \n",
    "    \n",
    "    # description of options:\n",
    "    # option 1: three clusters with few points\n",
    "    # option 2: two elongated clusters\n",
    "    # option 3: one large, one small cluster\n",
    "    # option 4: small, dense cluster within large cluster\n",
    "    # option 5: two ring-shaped clusters\n",
    "    # option 6: faithful.csv\n",
    "    \n",
    "    \n",
    "\n",
    "    # END parameters TODO: plot, von welcher normalverteilung Daten ursprÃ¼nglich erstellt\n",
    "    \n",
    "    if option == 1:\n",
    "        mean1 = np.array([1,0])\n",
    "        sig1 = 0.05*np.eye(2)\n",
    "        mean2 = np.array([0, 1])\n",
    "        sig2 = 0.05*np.eye(2)\n",
    "        mean3 = np.array([2, 1])\n",
    "        sig3 = 0.05*np.eye(2)\n",
    "        first = np.random.multivariate_normal(mean1, sig1, 5)\n",
    "        second = np.random.multivariate_normal(mean2, sig2, 5)\n",
    "        third = np.random.multivariate_normal(mean3, sig3, 5)\n",
    "        data = np.concatenate((first, second, third))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "    elif option == 2:\n",
    "        mean1 = np.array([1,0])\n",
    "        sig1 = np.diag([1.5, 0.05])\n",
    "        mean2 = np.array([1, 2])\n",
    "        sig2 = np.diag([1.5, 0.05])\n",
    "        data = np.concatenate((np.random.multivariate_normal(mean1, sig1, 25), np.random.multivariate_normal(mean2, sig2, 25)))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "    elif option == 3:\n",
    "        mean1 = np.array([4, 5])\n",
    "        sig1 = np.diag([0.5, 3])\n",
    "        mean2 = np.array([7, 5])\n",
    "        sig2 = np.diag([0.2, 0.2])\n",
    "        data = np.concatenate((np.random.multivariate_normal(mean1, sig1, 50), np.random.multivariate_normal(mean2, sig2, 10))) \n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "    elif option == 4:\n",
    "        mean1 = np.array([1, 1])\n",
    "        sig1 = np.diag([4, 4])\n",
    "        mean2 = np.array([3.5, 1])\n",
    "        sig2 = np.diag([0.01, 0.01])\n",
    "        data = np.concatenate((np.random.multivariate_normal(mean1, sig1, 50), np.random.multivariate_normal(mean2, sig2, 50)))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "    elif option == 5:\n",
    "        data1 = np.random.normal(0, 1, (40,2))\n",
    "        norms1 = np.tile(np.sqrt(data1[:,0]**2 + data1[:, 1]**2), (2, 1)).T\n",
    "        data1 = data1/(norms1) + np.random.normal(0, 0.05, (40,2))        \n",
    "        data2 = np.random.normal(0, 1, (40,2))\n",
    "        norms2 = np.tile(np.sqrt(data2[:,0]**2 + data2[:, 1]**2), (2, 1)).T\n",
    "        data2 = data2/(0.3*norms2) + np.random.normal(0, 0.05, (40,2))\n",
    "        data = np.concatenate((data1, data2))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "    elif option == 7: #singularity\n",
    "        mean1 = np.array([1,0])\n",
    "        sig1 = np.diag([0.5, 0.5])\n",
    "        mean2 = np.array([1, 2])\n",
    "        sig2 = np.diag([0.005, 0.005])\n",
    "        first = np.random.multivariate_normal(mean1, sig1, 2)\n",
    "        second = np.random.multivariate_normal(mean2, sig2, 10)\n",
    "        data = np.concatenate((first, second))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        choice = True\n",
    "        \n",
    "    elif option == 8: #maybe not a global maximum\n",
    "        data1 = np.random.normal(0, 1, (40,2))\n",
    "        norms1 = np.tile(np.sqrt(data1[:,0]**2 + data1[:, 1]**2), (2, 1)).T\n",
    "        first = data1/(norms1) + np.random.normal(0, 0.05, (40,2))        \n",
    "        data2 = np.random.normal(0, 1, (40,2))\n",
    "        norms2 = np.tile(np.sqrt(data2[:,0]**2 + data2[:, 1]**2), (2, 1)).T\n",
    "        second = data2/(0.3*norms2) + np.random.normal(0, 0.05, (40,2))\n",
    "        data = np.concatenate((first, second))\n",
    "        m1 = np.zeros((K, data.shape[1]))\n",
    "        choice = False\n",
    "        m1[0,0] = 0\n",
    "        m1[0,1] = -2\n",
    "        m1[1,0] = 0\n",
    "        m1[1,1] = 2\n",
    "        m2 = np.zeros((K, data.shape[1]))\n",
    "        m2[0,0] = 0\n",
    "        m2[0,1] = 0\n",
    "        m2[1,0] = 2\n",
    "        m2[1,1] = -2\n",
    "    elif option == 9: #no global maximum\n",
    "        mean1 = np.array([1,0])\n",
    "        sig1 = np.diag([1.5, 0.05])\n",
    "        mean2 = np.array([1, 2])\n",
    "        sig2 = np.diag([1.5, 0.05])\n",
    "        first = np.random.multivariate_normal(mean1, sig1, 20)\n",
    "        second = np.random.multivariate_normal(mean2, sig2, 20)\n",
    "        data = np.concatenate((first, second))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        m1 = np.zeros((K, data.shape[1]))\n",
    "        choice = False\n",
    "        m1[0,0] = 0\n",
    "        m1[0,1] = -2\n",
    "        m1[1,0] = 0\n",
    "        m1[1,1] = 2\n",
    "        m2 = np.zeros((K, data.shape[1]))\n",
    "        m2[0,0] = -2\n",
    "        m2[0,1] = -1\n",
    "        m2[1,0] = 2\n",
    "        m2[1,1] = -1\n",
    "    elif option == 10:\n",
    "        mean1 = np.array([-1,-2])\n",
    "        sig1 = np.diag([1.5, 0.05])\n",
    "        mean2 = np.array([1, 2])\n",
    "        sig2 = np.diag([1.5, 0.05])\n",
    "        first = np.random.multivariate_normal(mean1, sig1, 20)\n",
    "        second = np.random.multivariate_normal(mean2, sig2, 20)\n",
    "        data = np.concatenate((first, second))\n",
    "        m = np.zeros((K, data.shape[1]))\n",
    "        m1 = np.zeros((K, data.shape[1]))\n",
    "        choice = False\n",
    "        m1[0,0] = -2\n",
    "        m1[0,1] = 2\n",
    "        m1[1,0] = 4\n",
    "        m1[1,1] = -4\n",
    "        m2 = np.zeros((K, data.shape[1]))\n",
    "        m2[0,0] = -2\n",
    "        m2[0,1] = 2\n",
    "        m2[1,0] = 2\n",
    "        m2[1,1] = 2\n",
    "    # find bounding box of data (for plotting purposes)\n",
    "    xmin = np.min(data[:, 0])\n",
    "    xmax = np.max(data[:, 0])\n",
    "    ymin = np.min(data[:, 1])\n",
    "    ymax = np.max(data[:, 1])\n",
    "    dmin = min(xmin, ymin)\n",
    "    dmax = max(xmax, ymax)\n",
    "    \n",
    "    #data = np.concatenate((np.random.normal(0, 0.05, (10,)), np.random.normal(1, 0.05, (10,)))).reshape((-1,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def drawfig(it, m, m_history, n_iter, Sigma, Sigma_history, p, p_history, gamma, gamma_history):\n",
    "        plt.figure()\n",
    "        #ax1 = plt.subplot(1,2,1)\n",
    "        ax2 = plt.subplot(1,2,2)\n",
    "        #ax1.set_xlim([xmin-0.5, xmax+0.5])\n",
    "        #ax1.set_ylim([ymin-0.5, ymax+0.5])\n",
    "        m_now = m_history[it+1, :, :]\n",
    "        m_old = m_history[it, :, :]\n",
    "        \n",
    "        gamma_now = gamma_history[it+1, :]\n",
    "        Sigma_now = Sigma_history[it+1]\n",
    "        Sigma_old = Sigma_history[it]\n",
    "\n",
    "        \n",
    "        #for k in range(K):\n",
    "            #ax1.plot(m_old[k, 0], m_old[k, 1], color = colors[k], marker = \"s\", markeredgecolor=\"k\", markersize=10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if K == 2: # linear interpolation between colors possible\n",
    "            #mixcoeffs = gamma_now[:, 1]\n",
    "            #sc = ax1.scatter(data[:, 0], data[:, 1], c=[colorFader(colors[0],colors[1],mixc) for mixc in mixcoeffs], s=45, zorder=2)\n",
    "            \n",
    "        #else: # for more clusters we can only color with the dominant cluster :(\n",
    "            #cs_index = [int(list(gamma_now[n, :]).index(max(gamma_now[n, :]))) for n in range(N)]\n",
    "            #ax1.scatter(data[:, 0], data[:, 1], c=[colors[csi] for csi in cs_index], s=45, zorder=2)\n",
    "            \n",
    "        #for k in range(K):\n",
    "            #plot_ellipse(m_old[k, :], Sigma_old[k], ax1)\n",
    "            #plot_ellipse(m_old[k, :], Sigma_old[k], ax1, n_std=2.0)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        ax2.set_xlim([xmin-0.5, xmax+0.5])\n",
    "        ax2.set_ylim([ymin-0.5, ymax+0.5])\n",
    "        \n",
    "        for k in range(K):\n",
    "            ax2.plot(m_now[k, 0], m_now[k, 1], color = colors[k], marker = \"s\", markeredgecolor=\"k\", markersize=10)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                            \n",
    "        if K == 2: # linear interpolation between colors possible\n",
    "            mixcoeffs = gamma_now[:, 1]\n",
    "            sc = ax2.scatter(data[:, 0], data[:, 1], c=[colorFader(colors[0],colors[1],mixc) for mixc in mixcoeffs], s=45, zorder=2)\n",
    "            \n",
    "        else: # for more clusters we can only color with the dominant cluster :(\n",
    "            cs_index = [int(list(gamma_now[n, :]).index(max(gamma_now[n, :]))) for n in range(N)]\n",
    "            ax2.scatter(data[:, 0], data[:, 1], c=[colors[csi] for csi in cs_index], s=45, zorder=2)\n",
    "        #for k in range(K):\n",
    "            #plot_ellipse(m_now[k, :], Sigma_now[k], ax2)\n",
    "            #plot_ellipse(m_now[k, :], Sigma_now[k], ax2, n_std=2.0)\n",
    "        \n",
    "        #ax1.set_title(\"iteration \" + str(it) + \": after assignment\")\n",
    "        ax2.set_title(\"iteration \" + str(it) + \": after update\")\n",
    "        #plt.title(\"iteration \" + str(it) + \": after update\")\n",
    "        # ax1.set_aspect('equal')\n",
    "        # ax2.set_aspect('equal')\n",
    "        plt.show()\n",
    "    \n",
    "    def plotting(ret, just):\n",
    "        #if ret[\"success\"] == True:\n",
    "        m = ret[\"m\"]\n",
    "        m_history = ret[\"m_history\"]\n",
    "    \n",
    "        n_iter = m_history.shape[0] - 1\n",
    "    \n",
    "        Sigma = ret[\"Sigma\"]\n",
    "        Sigma_history = ret[\"Sigma_history\"]\n",
    "        p = ret[\"p\"]\n",
    "        p_history = ret[\"p_history\"]\n",
    "        gamma = ret[\"gamma\"]\n",
    "        gamma_history = ret[\"gamma_history\"]\n",
    "        likelihood = ret['likelihood']\n",
    "        print(first)\n",
    "        print(second)\n",
    "        #print(m_history)\n",
    "        #print(Sigma_history)\n",
    "        #print(likelihood)\n",
    "            \n",
    "        plt.ion()\n",
    "        #if ret[\"success\"] == True:\n",
    "        if just_last == True:\n",
    "            drawfig(m_history.shape[0]-3, m, m_history, n_iter, Sigma, Sigma_history, p, p_history, gamma, gamma_history)\n",
    "            #initial      \n",
    "            plt.figure()\n",
    "            ax1 = plt.subplot(1,2,1)\n",
    "            ax1.set_xlim([xmin-0.5, xmax+0.5])\n",
    "            ax1.set_ylim([ymin-0.5, ymax+0.5])\n",
    "            ax1.scatter(first[:, 0], first[:, 1])\n",
    "            ax1.scatter(second[:, 0], second[:, 1])\n",
    "            if option == 1:\n",
    "                ax1.scatter(third[:, 0], third[:, 1])\n",
    "            #ax1.set_title(\"initial clusters\")\n",
    "            plt.show()\n",
    "    \n",
    "            #likelihood\n",
    "            plt.figure()\n",
    "            ax1 = plt.subplot(1,1,1)\n",
    "            ax1.set_xlim([0, len(likelihood)-1])\n",
    "            ax1.set_ylim([min(likelihood)-1, max(likelihood)+1])\n",
    "            plt.plot(likelihood)\n",
    "            #ax1.set_title(\"values of loglikelihood\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            for it in range(m_history.shape[0]-2):\n",
    "                drawfig(it, m, m_history, n_iter, Sigma, Sigma_history, p, p_history, gamma, gamma_history)\n",
    "                #initial      \n",
    "                plt.figure()\n",
    "                ax1 = plt.subplot(1,2,1)\n",
    "                ax1.set_xlim([xmin-0.5, xmax+0.5])\n",
    "                ax1.set_ylim([ymin-0.5, ymax+0.5])\n",
    "                ax1.scatter(first[:, 0], first[:, 1])\n",
    "                ax1.scatter(second[:, 0], second[:, 1])\n",
    "                if option == 1:\n",
    "                    ax1.scatter(third[:, 0], third[:, 1])\n",
    "                ax1.set_title(\"initial clusters\")\n",
    "                plt.show()\n",
    "\n",
    "                #likelihood\n",
    "                plt.figure()\n",
    "                ax1 = plt.subplot(1,1,1)\n",
    "                ax1.set_xlim([0, len(likelihood)-1])\n",
    "                ax1.set_ylim([min(likelihood)-1, max(likelihood)+1])\n",
    "                plt.plot(likelihood)\n",
    "                ax1.set_title(\"values of loglikelihood\")\n",
    "                plt.show()\n",
    "    N, M = data.shape\n",
    "    just_last = True #parameter, if we only want to draw last\n",
    "    if option == 8 or option == 9 or option == 10:\n",
    "        ret1 = EM(data, K, m1, n_iter = n_iter, return_all_iterations=True, random_choice=choice)\n",
    "        plotting(ret1, just_last)\n",
    "        ret2 = EM(data, K, m2, n_iter = n_iter, return_all_iterations=True, random_choice=choice)\n",
    "        plotting(ret2, just_last)\n",
    "    else:\n",
    "        ret = EM(data, K, m, n_iter = n_iter, return_all_iterations=True, random_choice=choice)\n",
    "        plotting(ret, just_last)\n",
    "    \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
